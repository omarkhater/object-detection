{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> MCIT AWS Machine Learning Developer Program</center>\n",
    "## <center> Object Detection Model Using Images Labeled with Ground Truth </center>\n",
    "\n",
    "<figure class=\"image\">\n",
    "    <table><tr>\n",
    "    <td> <img src=\"./images/cover-object-detection.jfif\" alt=\"object-detection\" style=\"width: 1000px;\"/> </td>   \n",
    "    </tr></table>\n",
    "</figure>\n",
    "\n",
    "---\n",
    "\n",
    "# <u>Made by</u> :  <center> Omar Khater </center>\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# <center>Table of Contents</center>\n",
    "---\n",
    "<ul>\n",
    "<li><a href=\"#Introduction\">Introduction</a></li>\n",
    "  \n",
    "<li><a href=\"#Data\">Data Collection And Integration</a></li>\n",
    "\n",
    "<li><a href=\"#Model_Training\">Model Training And Evaluation </a></li>\n",
    "   \n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Introduction'></a>\n",
    "\n",
    "---\n",
    "# <center>Introduction</center>\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Object detection_ is a prominent _computer vision_ problem that aims not only to correctly classify the objects in a given image but also to label the locations of detected object instances. It is a _supervised learning_ algorithm that takes images as an input and identifies all instances of objects within the image scene. The object is categorized into one of the classes in a specified collection with a confidence score that it belongs to the class which its location and scale in the image are indicated by a rectangular bounding box. <br>\n",
    "\n",
    "<figure class=\"image\">\n",
    "    <table><tr>\n",
    "    <td> <img src=\"./images/object_detection.gif\" alt=\"object_detection\" style=\"width: 1000px;\"/> </td>   \n",
    "    </tr></table>\n",
    "</figure>\n",
    "\n",
    "This project builds an object dection solution for a dataset that has been labelled using `Ground Truth` and creates an endpoint to be used for real-time inference. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Data'></a>\n",
    "\n",
    "---\n",
    "# <center>Data Collection And Integration</center>\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset used in this problem is from the [inaturalist.org](inaturalist.org) and contains `500` images of _bees_ that have been uploaded by inaturalist users for the purposes of recording the observation and identification. The used images are that their users have licensed under [CC0](https://creativecommons.org/share-your-work/public-domain/cc0/) license. A labelling job that employs human labelers to create the bounding boxes ,using `Ground Truth`, is used to prepare the training set necessary to train the `machine learning` model.\n",
    "\n",
    "_**[Amazon SageMaker Ground Truth](https://aws.amazon.com/sagemaker/groundtruth/)**_ is a data labeling service that makes it easy to build highly accurate training datasets for machine learning. As part of the workflow, labelers have access to assistive labeling features such as automatic 3D cuboid snapping, removal of distortion in 2D images, and auto-segment tools to reduce the time required to label datasets. <br>\n",
    "\n",
    "<figure class=\"image\">\n",
    "    <table><tr>\n",
    "    <td> <img src=\"./images/GroundTruth.png\" alt=\"GroundTruth\" style=\"width: 1000px; height: 600px;\"/> </td>   \n",
    "    </tr></table>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Model_Training'></a>\n",
    "\n",
    "---\n",
    "# <center>Model Training And Evaluation </center>\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_**[Single Shot multibox Detector (SSD)](https://arxiv.org/pdf/1512.02325.pdf)**_ ,the built-in framework employed by `Amazon SageMaker` for _**[Object Detection Algorithm](https://docs.aws.amazon.com/sagemaker/latest/dg/object-detection.html)**_ ,is based on a _**feed-forward convolutional network**_ that produces a fixed-size collection of bounding boxes and scores for the presence of object class instances in those boxes, followed by a non-maximum suppression step to produce the final detections.<br>\n",
    "\n",
    "\n",
    "<figure class=\"image\">\n",
    "    <table><tr>\n",
    "    <td> <img src=\"./images/SSD2.JPG\" alt=\"SSD\" style=\"width: 1000px; height: 500px;\"/> </td>   \n",
    "    </tr></table>\n",
    "    <table><tr>\n",
    "    <td> <img src=\"./images/object_detection2.gif\" alt=\"SSD\" style=\"width: 1000px; height: 500px;\"/> </td>   \n",
    "    </tr></table>\n",
    "    <center><figcaption>Above: Networks of Single-shot Multibox Detector (SSD) and Multiheaded Attention Net (MANet). The blue modules are the layers added in the SSD framework and are referred to as the SSD layers. The green layers are the MANet layers (where conv1_x, conv2_x, conv3_x, conv4_x, conv5_x, are the convolution feature layers at different scales).<br>\n",
    "Below: Object detection and multi-object tracking using SSD \n",
    "        </figcaption></center>\n",
    "    \n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  mean Average Precision (mAP) for Object Detection\n",
    "\n",
    "The average precision (AP) is the area under the precision-recall curve. \n",
    "\n",
    "mean average precision is the average of all the average precisions(APs) of all classes in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The whole training job is reported in [Data Preparation And Model Training ](object-detection-model-training.html) with the following key parameters: \n",
    "\n",
    "- The model used ResNet-50 as a base network for SSD. \n",
    "- The model is trained in transfer learning mode i.e., the base network weights are loaded from pretrained models. \n",
    "\n",
    "\n",
    "The training results are shown below \n",
    "\n",
    "<figure class=\"image\">\n",
    "    <table><tr>\n",
    "    <td> <img src=\"./images/TrainingResults.JPG\" alt=\"TrainingResults\" style=\"width: 1000px; height: 500px;\"/> </td>   \n",
    "    </tr></table>\n",
    "    <center><figcaption> Training results\n",
    "        </figcaption></center>\n",
    "    \n",
    "</figure>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
